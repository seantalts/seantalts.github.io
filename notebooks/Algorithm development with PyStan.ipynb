{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Executive summary\n",
    "You can use Stan to write a statistical model and easily compile it to efficient C++ and native code, and cause it to be linked in to a running Python (or R) process while giving you access to not just the obvious HMC sampling methods but also the underying posterior density function $\\pi(y \\, | \\theta)$ and its gradient under `log_prob` and `grad_log_prob`, respectively. This document shows how to do that in Python.\n",
    "\n",
    "# Context\n",
    "On the [Stan](http://mc-stan.org) team, we get a lot of questions from people looking to use Stan for algorithm development. Stan is opinionated software and believes that models are mostly separate from inference mechanisms, so most of the people looking to do algorithm development with us buy into that; they're looking to perhaps add some mechanism for discrete parameters or maybe add another type of approximation alternative to [ADVI](https://arxiv.org/abs/1506.03431) for a given statistical model. \n",
    "\n",
    "I claim that this version is actually pretty easy to do in practice, but we haven't written anything up about it because the Stan team values robustness and generality first and foremost, and we're eagerly awaiting something that beats the No U-Turn Sampler (which has since been improved in our source code from the [original paper](https://arxiv.org/abs/1111.4246)). There are a few of us who would like to support the broader research community in using Stan for algorithm development, even if we do not include any of these algorithms with the distribution of Stan. This document should illustrate how this can work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_390a0ec538f0cb4f0a4483ba147e0080 NOW.\n"
     ]
    }
   ],
   "source": [
    "# Construct an arbitrary model\n",
    "model_code = \"\"\"\n",
    "data {\n",
    "  int numObs;\n",
    "  int numGroups;\n",
    "  matrix[numObs, numGroups] group;\n",
    "  vector[numObs] y;\n",
    "}\n",
    "parameters {\n",
    "  vector[numGroups] beta;\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "model {\n",
    "  beta ~ normal(0, 20);\n",
    "  sigma ~ normal(0, 5);\n",
    "  y ~ normal(group * beta, sigma);\n",
    "}\n",
    "\"\"\"\n",
    "model = pystan.StanModel(model_code=model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma: 9.157885217081992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'group': array([[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]]),\n",
       " 'y': array([-24.76301019, -35.97887663, -20.23274477, -41.49054707,\n",
       "        -16.02999448, -34.09165568, -24.88020563, -24.05463857,\n",
       "        -16.86881039, -18.8714874 , -30.42428944, -11.29308102,\n",
       "        -24.34802981, -29.40753916, -28.59344693, -32.39550442,\n",
       "        -36.37132741, -16.20657938, -24.92878376, -13.25484089,\n",
       "        -13.17939153, -19.27899561, -35.26058827, -15.55430219,\n",
       "        -12.2679381 ,  -7.88959863, -22.76132319, -25.95365739,\n",
       "        -25.42946611, -18.30691545, -17.3644884 , -12.23038274,\n",
       "        -26.18277742, -32.8749564 , -27.22624725, -26.41887204,\n",
       "        -16.35451777, -20.67424802, -27.49359065, -24.22740679,\n",
       "        -16.48492267, -14.92948987, -39.5280163 , -16.32757889,\n",
       "        -18.03326048, -16.02600095, -24.86888698, -11.08624993,\n",
       "        -39.63109918, -21.36258758, -37.90687437, -26.49305471,\n",
       "        -19.65015011, -29.10433207, -22.13268255, -31.98791592,\n",
       "          3.45796284, -26.93794208, -21.262007  , -26.21311793,\n",
       "         -9.91721967, -28.45472649, -25.29096601, -15.85858002,\n",
       "        -19.52721789, -22.61223839, -16.48710779, -17.49848262,\n",
       "        -27.80772762,  -6.55352763, -38.28107976, -40.83528445,\n",
       "        -25.64275568, -20.9426822 , -39.5144073 , -12.74040907,\n",
       "        -13.68907224, -25.04254282, -16.91582672, -36.15031289,\n",
       "        -25.97056788, -18.37441026, -26.20311141, -20.06767311,\n",
       "        -33.2656917 , -33.07670545, -34.38271064, -23.44184368,\n",
       "        -23.32873611,  -1.62293945, -27.85781366, -16.54050565,\n",
       "         -8.79686481, -34.06324398, -21.78571493, -16.59197712,\n",
       "        -22.35961064, -31.80027921, -30.64009453, -25.19952429]),\n",
       " 'numObs': 100,\n",
       " 'numGroups': 3,\n",
       " 'beta': array([-25.87069529, -22.30629952, -19.12452159])}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fake data\n",
    "def gen_fake_data(N=100, K=3):\n",
    "    group_ = np.random.choice(K, N)\n",
    "    # one-hot encode in matrix\n",
    "    group = np.zeros((N, K))\n",
    "    group[np.arange(N), group_] = 1\n",
    "    beta = np.random.normal(0, 20, K)\n",
    "    sigma = np.abs(np.random.normal(0, 5))\n",
    "    print(\"sigma: {}\".format(sigma))\n",
    "    y = np.random.normal(group.dot(beta), sigma)\n",
    "    return dict(group=group, y=y, numObs=N, numGroups=K, beta=beta)\n",
    "fd = gen_fake_data()\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_390a0ec538f0cb4f0a4483ba147e0080.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "          mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "beta[1]  -24.4    0.02   1.45 -27.25 -25.37 -24.42 -23.46 -21.52   5131    1.0\n",
       "beta[2] -23.44    0.02   1.45 -26.26 -24.43 -23.46 -22.46 -20.59   4251    1.0\n",
       "beta[3] -20.77    0.03   1.74 -24.19 -21.93 -20.79 -19.66 -17.22   4088    1.0\n",
       "sigma     8.81    0.01   0.63   7.68   8.36   8.79   9.22  10.14   3649    1.0\n",
       "lp__    -269.8    0.03   1.47 -273.5 -270.5 -269.4 -268.7 -268.0   1796    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Sat Oct 20 22:47:52 2018.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You must first run one of the methods that gives you a fit object:\n",
    "fit = model.sampling(data=fd)\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grad_log_prob', 'log_prob']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This then exposes a log prob and grad_log_prob method:\n",
    "list(filter(lambda x: \"prob\" in x, dir(fit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function log_prob:\n",
      "\n",
      "log_prob(...) method of stanfit4anon_model_390a0ec538f0cb4f0a4483ba147e0080_913984840570262847.StanFit4Model instance\n",
      "    Expose the log_prob of the model to stan_fit so user can call\n",
      "    this function.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    upar : array\n",
      "        The real parameters on the unconstrained space.\n",
      "    adjust_transform : bool\n",
      "        Whether we add the term due to the transform from constrained\n",
      "        space to unconstrained space implicitly done in Stan.\n",
      "    \n",
      "    Note\n",
      "    ----\n",
      "    In Stan, the parameters need be defined with their supports. For\n",
      "    example, for a variance parameter, we must define it on the positive\n",
      "    real line. But inside Stan's sampler, all parameters defined on the\n",
      "    constrained space are transformed to unconstrained space, so the log\n",
      "    density function need be adjusted (i.e., adding the log of the absolute\n",
      "    value of the Jacobian determinant).  With the transformation, Stan's\n",
      "    samplers work on the unconstrained space and once a new iteration is\n",
      "    drawn, Stan transforms the parameters back to their supports. All the\n",
      "    transformation are done inside Stan without interference from the users.\n",
      "    However, when using the log density function for a model exposed to\n",
      "    Python, we need to be careful.  For example, if we are interested in\n",
      "    finding the mode of parameters on the constrained space, we then do not\n",
      "    need the adjustment.  For this reason, there is an argument named\n",
      "    `adjust_transform` for functions `log_prob` and `grad_log_prob`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fit.log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-386.70221104212527"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.log_prob(upar=np.arange(4)) # adjust_transform seems to default to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beta[1]', 'beta[2]', 'beta[3]', 'sigma']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-764.6526305472523"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can pass parameter values to `log_prob` in the order we defined them,\n",
    "# which is shown in `flatnames`\n",
    "print(fit.flatnames)\n",
    "fit.log_prob(upar=[-50, 40, 32, 2.8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization\n",
    "[Expectation maximization](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) can be thought of as a generalization of [k-means](https://en.wikipedia.org/wiki/K-means_clustering) with discrete cluster assignments to models that have additional parameters (that might be dependent on the cluster assigments). Bob Carpenter has [a good write-up](https://discourse.mc-stan.org/t/tutorial-on-monte-carlo-em-and-variants-for-mml-and-mmap/5173); I'll try to summarize the algorithm briefly here.\n",
    "\n",
    "The algorithm is traditionally explained as broken up into two steps, one for calculating the expectation of the cluster assignments (or other latent parameters) and using those to generate the assignments, and another for maximizing the values of the other parameters given those assignments. One way to accomplish this with Stan is to provide two Stan models, one for each step. I'll call these `expectation.stan` and `maximization.stan` and use Markov Chain Monte Carlo to calculate the integral in the expectation step, and our BFGS optimizer for the maximization step. The model we already defined can be used as is for the maximization step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_5fb00b74056ca004b9d6262d4b3f4b40 NOW.\n"
     ]
    }
   ],
   "source": [
    "expectation_model = pystan.StanModel(model_code=\"\"\"\n",
    "data {\n",
    "  int numObs;\n",
    "  int numGroups;\n",
    "  row_vector[numGroups] beta;\n",
    "  vector[numObs] y;\n",
    "}\n",
    "parameters {\n",
    "  simplex[numGroups] group[numObs];\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "model {\n",
    "  vector[numObs] mu;\n",
    "  for (n in 1:numObs)\n",
    "    mu[n] = beta * group[n];\n",
    "  beta ~ normal(0, 20);\n",
    "  sigma ~ normal(0, 5);\n",
    "  y ~ normal(mu, sigma);\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "efit = expectation_model.sampling(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34287063, 0.33352272, 0.32360666],\n",
       "       [0.38534671, 0.33009014, 0.28456314],\n",
       "       [0.32387381, 0.33703026, 0.33909593],\n",
       "       [0.40500117, 0.32694373, 0.2680551 ],\n",
       "       [0.30960678, 0.33668936, 0.35370385],\n",
       "       [0.38028181, 0.32616916, 0.29354904],\n",
       "       [0.34636906, 0.33375806, 0.31987287],\n",
       "       [0.33912141, 0.33499342, 0.32588517],\n",
       "       [0.31187386, 0.33640507, 0.35172107],\n",
       "       [0.31823332, 0.33544074, 0.34632594],\n",
       "       [0.365601  , 0.33248204, 0.30191696],\n",
       "       [0.28854845, 0.33530351, 0.37614805],\n",
       "       [0.33981265, 0.33450326, 0.32568408],\n",
       "       [0.35817954, 0.33082139, 0.31099908],\n",
       "       [0.3564163 , 0.33486351, 0.30872019],\n",
       "       [0.36999923, 0.32687867, 0.3031221 ],\n",
       "       [0.38540445, 0.3306891 , 0.28390645],\n",
       "       [0.30736623, 0.33507612, 0.35755765],\n",
       "       [0.34348607, 0.33116681, 0.32534712],\n",
       "       [0.29724348, 0.34231639, 0.36044012],\n",
       "       [0.29648312, 0.33735369, 0.36616319],\n",
       "       [0.32303331, 0.33817898, 0.33878772],\n",
       "       [0.38482209, 0.33393063, 0.28124728],\n",
       "       [0.30477306, 0.34342669, 0.35180025],\n",
       "       [0.29378647, 0.33673974, 0.36947379],\n",
       "       [0.27940436, 0.33181731, 0.38877833],\n",
       "       [0.33700281, 0.32880412, 0.33419307],\n",
       "       [0.35008759, 0.33203349, 0.31787893],\n",
       "       [0.341904  , 0.33428086, 0.32381514],\n",
       "       [0.31659466, 0.34048897, 0.34291637],\n",
       "       [0.31213773, 0.33853292, 0.34932936],\n",
       "       [0.2975474 , 0.3326255 , 0.3698271 ],\n",
       "       [0.34441398, 0.3374758 , 0.31811022],\n",
       "       [0.36932187, 0.33308847, 0.29758966],\n",
       "       [0.35248184, 0.32950247, 0.3180157 ],\n",
       "       [0.34158105, 0.33346443, 0.32495452],\n",
       "       [0.3115484 , 0.33251778, 0.35593381],\n",
       "       [0.32768694, 0.33530042, 0.33701264],\n",
       "       [0.3556731 , 0.33457808, 0.30974883],\n",
       "       [0.33513205, 0.33868246, 0.32618548],\n",
       "       [0.3133958 , 0.33711971, 0.34948449],\n",
       "       [0.30058265, 0.33728532, 0.36213203],\n",
       "       [0.39701214, 0.32487156, 0.2781163 ],\n",
       "       [0.31003051, 0.33696047, 0.35300902],\n",
       "       [0.31507269, 0.33560426, 0.34932305],\n",
       "       [0.31021775, 0.33016678, 0.35961548],\n",
       "       [0.34135534, 0.33826867, 0.32037599],\n",
       "       [0.29200219, 0.32743109, 0.38056673],\n",
       "       [0.40319877, 0.31963511, 0.27716612],\n",
       "       [0.32399511, 0.33651557, 0.33948933],\n",
       "       [0.39977861, 0.31784658, 0.28237481],\n",
       "       [0.34787149, 0.33451137, 0.31761714],\n",
       "       [0.32097827, 0.33947071, 0.33955101],\n",
       "       [0.35648301, 0.33485839, 0.3086586 ],\n",
       "       [0.33196652, 0.34094046, 0.32709302],\n",
       "       [0.37365912, 0.32566742, 0.30067345],\n",
       "       [0.24134901, 0.32549151, 0.43315948],\n",
       "       [0.35092544, 0.32931826, 0.3197563 ],\n",
       "       [0.32713939, 0.3340415 , 0.3388191 ],\n",
       "       [0.3445855 , 0.33581984, 0.31959466],\n",
       "       [0.28458706, 0.32990013, 0.38551281],\n",
       "       [0.35346086, 0.3316976 , 0.31484154],\n",
       "       [0.34129134, 0.33475361, 0.32395505],\n",
       "       [0.3064556 , 0.33752965, 0.35601475],\n",
       "       [0.32450495, 0.33245313, 0.34304191],\n",
       "       [0.33238082, 0.33552745, 0.33209173],\n",
       "       [0.30958675, 0.33779734, 0.35261591],\n",
       "       [0.31546996, 0.33175084, 0.35277919],\n",
       "       [0.35249988, 0.3320711 , 0.31542902],\n",
       "       [0.28117601, 0.33175963, 0.38706436],\n",
       "       [0.39248767, 0.33024124, 0.27727109],\n",
       "       [0.40543733, 0.32589654, 0.26866613],\n",
       "       [0.34183759, 0.33303631, 0.32512609],\n",
       "       [0.32910034, 0.33661346, 0.3342862 ],\n",
       "       [0.4028977 , 0.32794648, 0.26915582],\n",
       "       [0.29476089, 0.33606029, 0.36917882],\n",
       "       [0.30436192, 0.32904527, 0.36659281],\n",
       "       [0.34415467, 0.33755391, 0.31829141],\n",
       "       [0.31382047, 0.33479953, 0.35138   ],\n",
       "       [0.38430372, 0.32879984, 0.28689644],\n",
       "       [0.34318061, 0.33552953, 0.32128986],\n",
       "       [0.32192371, 0.33495585, 0.34312045],\n",
       "       [0.34739747, 0.33168742, 0.32091512],\n",
       "       [0.3189436 , 0.3378379 , 0.34321851],\n",
       "       [0.37289842, 0.33002759, 0.29707399],\n",
       "       [0.37055856, 0.33581998, 0.29362146],\n",
       "       [0.37861279, 0.3366816 , 0.28470561],\n",
       "       [0.3380775 , 0.33352739, 0.32839511],\n",
       "       [0.33620868, 0.33383518, 0.32995613],\n",
       "       [0.25938512, 0.33104001, 0.40957486],\n",
       "       [0.35733385, 0.33211797, 0.31054818],\n",
       "       [0.31152776, 0.33670355, 0.3517687 ],\n",
       "       [0.28416663, 0.33328579, 0.38254758],\n",
       "       [0.38168433, 0.32675101, 0.29156466],\n",
       "       [0.33166049, 0.3333332 , 0.33500632],\n",
       "       [0.30982378, 0.33653353, 0.3536427 ],\n",
       "       [0.33162061, 0.3363138 , 0.33206558],\n",
       "       [0.36990843, 0.32760897, 0.30248259],\n",
       "       [0.36067618, 0.33575575, 0.30356807],\n",
       "       [0.34506902, 0.33535388, 0.3195771 ]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = efit.extract()['group']\n",
    "np.mean(g, axis=0) # shitty group assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original beta: [-116.43297767   72.04383948   38.9385973 ]\n",
      "Iteration 0; beta: [41.25547549 -1.77402583 48.43987292]\n",
      "Iteration 1; beta: [  34.72164799 -112.12691211   46.61467111]\n"
     ]
    }
   ],
   "source": [
    "def em_algo(maxi_model, expectation_model, data, num_iter=10):\n",
    "    print(\"Original beta: {}\".format(data['beta']))\n",
    "    #Random initialization for parameters\n",
    "    data['beta'] = np.random.normal(0, 20, len(data['beta']))\n",
    "    for i in range(num_iter):\n",
    "        print(\"Iteration {}; beta: {}\".format(i, data['beta']))\n",
    "        # E step\n",
    "        efit = expectation_model.sampling(data)\n",
    "        data['group'] = np.mean(efit.extract()['group'], axis=0)\n",
    "        \n",
    "        # M step\n",
    "        mfit = maxi_model.optimizing(data)\n",
    "        data['beta'] = mfit['beta']\n",
    "em_algo(maxi_model, expectation_model, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
